# Enhanced LLM Policy Arbitration Configuration
# Optimized for Zelda Oracle of Seasons RL Training

# PPO Base Configuration
ppo:
  learning_rate: 3e-4
  gamma: 0.99
  gae_lambda: 0.95
  clip_epsilon: 0.2
  value_loss_coeff: 0.5
  entropy_coeff: 0.01
  max_grad_norm: 0.5

# Enhanced Planner Integration with Smart Arbitration
planner_integration:
  use_planner: true
  
  # RESEARCH-BASED FREQUENCY OPTIMIZATION
  base_planner_frequency: 200      # Every ~13 seconds at 15fps (was 100)
  min_planner_frequency: 50        # Never more frequent than ~3 seconds
  max_planner_frequency: 500       # Never less frequent than ~33 seconds
  
  # ADAPTIVE FREQUENCY MODIFIERS
  exploration_bonus_multiplier: 0.6  # Reduce calls when exploring well
  stuck_penalty_multiplier: 1.8     # Increase calls when stuck
  
  # CONTEXT-AWARE TRIGGERS (Smart Arbitration)
  trigger_on_new_room: true         # üó∫Ô∏è  Call LLM when entering new areas
  trigger_on_low_health: true       # ‚ù§Ô∏è  Call LLM when health critical
  trigger_on_stuck: true            # üö´ Call LLM when no progress
  trigger_on_npc_interaction: true  # üí¨ Call LLM for dialogue opportunities
  trigger_on_dungeon_entrance: true # üè∞ Call LLM when entering dungeons
  
  # PERFORMANCE THRESHOLDS
  stuck_threshold: 75               # Steps without progress = stuck (was 50)
  low_health_threshold: 0.25        # Health % to trigger LLM (was 0.3)
  exploration_rate_threshold: 0.08  # New areas per episode
  
  # MACRO EXECUTION OPTIMIZATION
  macro_timeout: 75                 # Max steps per macro (was 200!)
  max_concurrent_macros: 1          # One macro at a time
  
  # PERFORMANCE TRACKING
  track_arbitration_performance: true
  arbitration_success_window: 100   # Steps to measure success

# Environment Configuration
environment:
  frame_skip: 4
  action_repeat: 1
  observation_type: "vector"
  normalize_observations: true
  max_episode_steps: 8000          # Reduced for faster iteration

# Enhanced Rewards (Using our exploration system)
rewards:
  # Base rewards
  time_penalty: -0.0001
  movement_reward: 0.001
  death_penalty: -3.0
  
  # EXPLORATION REWARDS (Our breakthrough system!)
  room_discovery_reward: 10.0      # Big bonus for new areas
  dungeon_discovery_reward: 25.0   # Massive bonus for dungeon entry
  dungeon_bonus: 5.0               # Continuous bonus while in dungeon
  npc_interaction_reward: 15.0     # Big bonus for talking to NPCs
  
  # Additional smart rewards
  stuck_penalty: -0.1              # Penalty for being stuck
  macro_success_reward: 2.0        # Bonus when macro completes successfully

# Training Configuration
training:
  total_timesteps: 500000          # Reduced for testing
  eval_frequency: 25000
  save_frequency: 50000
  log_frequency: 500
  
  # Episode management optimized for Zelda
  early_termination:
    health_zero: true
    stuck_threshold: 200           # Terminate if stuck too long

# Logging Enhanced Arbitration Metrics
logging:
  track_metrics:
    - "episode_reward"
    - "episode_length"
    - "rooms_discovered"
    - "llm_arbitration_calls"
    - "arbitration_success_rate"
    - "macro_completion_rate"
    - "stuck_episodes"
    - "exploration_rate"
    - "npc_interactions"
    - "dungeon_entries"

# Hardware
hardware:
  device: "auto"
  num_workers: 1
