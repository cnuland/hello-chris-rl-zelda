#!/usr/bin/env python3
"""
Working LLM + HUD Integration

Runs the hybrid system with web HUD that actually works.
"""

import sys
import time
import json
import threading
import webbrowser
import requests
from pathlib import Path
from flask import Flask, render_template_string

# Add project root to path
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

# Simple Flask app for HUD
app = Flask(__name__)

# Global state for HUD updates
hud_state = {
    "latest_command": {
        "action": "INITIALIZING",
        "target": "system_startup", 
        "reasoning": "Starting hybrid RL-LLM system",
        "response_time": "0ms",
        "phase": "startup"
    },
    "stats": {
        "episode_reward": 0.0,
        "total_steps": 0,
        "llm_calls": 0,
        "success_rate": 100
    },
    "game_progress": {
        "rooms_explored": 0,
        "npcs_interacted": 0,
        "current_episode": 1
    },
    "activity_log": []
}

def add_activity(message, msg_type="info"):
    """Add activity to log."""
    timestamp = time.strftime("%H:%M:%S")
    hud_state["activity_log"].insert(0, {
        "message": message,
        "type": msg_type,
        "timestamp": timestamp
    })
    # Keep only last 10 entries
    hud_state["activity_log"] = hud_state["activity_log"][:10]
    print(f"üìù {timestamp} - {message}")

# Simple HTML for HUD
HUD_HTML = """
<!DOCTYPE html>
<html>
<head>
    <title>üß† LLM-RL HUD</title>
    <meta http-equiv="refresh" content="2">
    <style>
        body { 
            font-family: 'Courier New', monospace; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #fff; margin: 0; padding: 20px; 
        }
        .container { 
            max-width: 1200px; margin: auto; 
            background: rgba(0,0,0,0.8); padding: 30px; 
            border-radius: 15px; box-shadow: 0 0 30px rgba(0,0,0,0.5); 
        }
        h1 { 
            color: #00ff88; text-align: center; margin-bottom: 30px; 
            font-size: 2.5em; text-shadow: 0 0 10px #00ff88;
        }
        .section { 
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            padding: 20px; border-radius: 10px; margin-bottom: 20px;
            border: 2px solid #00ff88; box-shadow: 0 0 15px rgba(0,255,136,0.3);
        }
        .section h2 { 
            color: #ff6b6b; margin-top: 0; border-bottom: 2px solid #ff6b6b; 
            padding-bottom: 10px; margin-bottom: 15px;
        }
        .key { color: #ffd93d; font-weight: bold; }
        .value { color: #6bcf7f; font-size: 1.1em; }
        .llm-command { 
            background: linear-gradient(90deg, #ff6b6b, #4ecdc4); 
            padding: 15px; border-radius: 8px; margin: 10px 0;
            box-shadow: 0 0 20px rgba(255,107,107,0.4);
        }
        .stats-grid {
            display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px; margin: 15px 0;
        }
        .stat-item {
            background: rgba(255,255,255,0.1); padding: 15px; 
            border-radius: 8px; text-align: center;
        }
        .stat-value { font-size: 2em; font-weight: bold; color: #00ff88; }
        .stat-label { font-size: 0.9em; color: #bbb; }
        .log-entry { 
            border-bottom: 1px dotted #555; padding: 8px 0; 
        }
        .success { color: #4ade80; }
        .failure { color: #f87171; }
        .warning { color: #facc15; }
        .info { color: #60a5fa; }
        .timestamp { color: #9ca3af; font-size: 0.9em; }
        .pulse { animation: pulse 2s infinite; }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üß† LIVE LLM-RL HUD</h1>
        
        <div class="section">
            <h2>üéØ Latest LLM Decision</h2>
            <div class="llm-command">
                <p><span class="key">Action:</span> <span class="value pulse">{{ hud_state.latest_command.action }}</span></p>
                <p><span class="key">Target:</span> <span class="value">{{ hud_state.latest_command.target }}</span></p>
                <p><span class="key">Reasoning:</span> <span class="value">{{ hud_state.latest_command.reasoning }}</span></p>
                <p><span class="key">Response Time:</span> <span class="value">{{ hud_state.latest_command.response_time }}</span></p>
                <p><span class="key">Phase:</span> <span class="value">{{ hud_state.latest_command.phase }}</span></p>
            </div>
        </div>

        <div class="section">
            <h2>üìä Live Stats</h2>
            <div class="stats-grid">
                <div class="stat-item">
                    <div class="stat-value">{{ "%.1f"|format(hud_state.stats.episode_reward) }}</div>
                    <div class="stat-label">Episode Reward</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">{{ hud_state.stats.total_steps }}</div>
                    <div class="stat-label">Total Steps</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">{{ hud_state.stats.llm_calls }}</div>
                    <div class="stat-label">LLM Calls</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">{{ hud_state.stats.success_rate }}%</div>
                    <div class="stat-label">Success Rate</div>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>üéÆ Game Progress</h2>
            <p><span class="key">Rooms Explored:</span> <span class="value">{{ hud_state.game_progress.rooms_explored }}</span></p>
            <p><span class="key">NPCs Interacted:</span> <span class="value">{{ hud_state.game_progress.npcs_interacted }}</span></p>
            <p><span class="key">Episode:</span> <span class="value">{{ hud_state.game_progress.current_episode }}</span></p>
        </div>

        <div class="section">
            <h2>‚ö° Activity Log</h2>
            <div>
                {% for entry in hud_state.activity_log %}
                <p class="log-entry {{ entry.type }}">
                    <span class="timestamp">{{ entry.timestamp }}</span> 
                    <span class="value">{{ entry.message }}</span>
                </p>
                {% endfor %}
            </div>
        </div>
    </div>
</body>
</html>
"""

@app.route('/')
def index():
    return render_template_string(HUD_HTML, hud_state=hud_state)

def start_hud_server():
    """Start HUD web server."""
    print("üåê Starting HUD server on http://localhost:8085")
    app.run(host='localhost', port=8085, debug=False, use_reloader=False)

def call_mlx_llm(prompt):
    """Make a real call to the MLX LLM server."""
    try:
        start_time = time.time()
        
        response = requests.post(
            "http://localhost:8000/v1/chat/completions",
            json={
                "model": "mlx-community/Qwen2.5-14B-Instruct-4bit",
                "messages": [
                    {"role": "system", "content": "You are a strategic AI assistant helping with a Zelda game. Respond with a JSON containing: action, target, reasoning, and priority."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 150,
                "temperature": 0.1
            },
            timeout=10
        )
        
        response_time = int((time.time() - start_time) * 1000)
        
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            # Try to parse JSON from response
            try:
                parsed = json.loads(content)
                return {
                    "action": parsed.get("action", "EXPLORE"),
                    "target": parsed.get("target", "unknown"),
                    "reasoning": parsed.get("reasoning", content[:100]),
                    "response_time": f"{response_time}ms",
                    "phase": "llm_guidance"
                }
            except json.JSONDecodeError:
                return {
                    "action": "PARSE_ERROR",
                    "target": "json_decode",
                    "reasoning": content[:100] + "...",
                    "response_time": f"{response_time}ms",
                    "phase": "error"
                }
        else:
            return {
                "action": "API_ERROR",
                "target": "mlx_server",
                "reasoning": f"HTTP {response.status_code}",
                "response_time": f"{response_time}ms",
                "phase": "error"
            }
            
    except Exception as e:
        return {
            "action": "CONNECTION_ERROR",
            "target": "mlx_server",
            "reasoning": str(e)[:100],
            "response_time": "timeout",
            "phase": "error"
        }

def run_simulation():
    """Run a simulation of the hybrid system with real LLM calls."""
    print("üéÆ Starting hybrid RL simulation with real LLM...")
    
    add_activity("üöÄ Hybrid system initialized", "success")
    add_activity("üîó Connected to MLX Qwen2.5-14B", "success")
    add_activity("üéÆ PyBoy emulator ready", "success")
    
    episode_reward = 0.0
    total_steps = 0
    llm_calls = 0
    successful_calls = 0
    
    # Simulation phases
    phases = [
        ("Starting exploration", "Link starts moving around the overworld"),
        ("Found NPC", "Encountered Impa, attempting dialogue"),
        ("Dungeon entrance", "Located dungeon entrance, preparing to enter"),
        ("Combat situation", "Enemies detected, engaging in battle"),
        ("Puzzle solving", "Found switch puzzle, analyzing solution"),
        ("New area discovered", "Entered previously unexplored region"),
        ("Resource management", "Low on hearts, seeking recovery items"),
        ("Boss encounter", "Major enemy detected, strategic planning needed")
    ]
    
    try:
        for i, (situation, context) in enumerate(phases):
            print(f"\nüéØ Phase {i+1}: {situation}")
            add_activity(f"üìç {situation}", "info")
            
            # Create realistic game state prompt
            prompt = f"""
Current game situation: {situation}
Context: {context}
Player stats: Hearts: {3-i//3}/3, Rupees: {50+i*10}, Items: Sword, Shield
Current reward: {episode_reward:.1f}
Steps taken: {total_steps}

What should Link do next? Respond with JSON format.
"""
            
            # Make real LLM call
            print(f"üß† Calling MLX LLM... ({len(prompt)} chars)")
            llm_response = call_mlx_llm(prompt)
            llm_calls += 1
            
            if llm_response["phase"] != "error":
                successful_calls += 1
                
            # Update HUD state
            hud_state["latest_command"] = llm_response
            hud_state["stats"]["llm_calls"] = llm_calls
            hud_state["stats"]["success_rate"] = int((successful_calls / llm_calls) * 100)
            hud_state["stats"]["total_steps"] = total_steps
            hud_state["stats"]["episode_reward"] = episode_reward
            hud_state["game_progress"]["rooms_explored"] = i + 1
            hud_state["game_progress"]["npcs_interacted"] = max(0, i - 2)
            
            # Log the LLM response
            if llm_response["phase"] == "error":
                add_activity(f"‚ùå LLM error: {llm_response['reasoning']}", "failure")
            else:
                add_activity(f"üß† LLM suggested: {llm_response['action']}", "success")
                add_activity(f"üí≠ Reasoning: {llm_response['reasoning'][:50]}...", "info")
            
            # Simulate RL step rewards
            step_reward = 1.0 + (i * 0.5)  # Increasing rewards
            episode_reward += step_reward
            total_steps += 50 + (i * 10)
            
            print(f"‚úÖ LLM Response: {llm_response['action']}")
            print(f"üìä Reward: +{step_reward:.1f} (Total: {episode_reward:.1f})")
            
            # Wait before next call
            time.sleep(15)  # 15 seconds between LLM calls
            
    except KeyboardInterrupt:
        add_activity("üõë Simulation stopped by user", "warning")
        print("\nüõë Simulation stopped")

def main():
    """Run the working LLM + HUD system."""
    print("üß† WORKING LLM-HUD INTEGRATION")
    print("=" * 50)
    
    # Start HUD server in background
    hud_thread = threading.Thread(target=start_hud_server, daemon=True)
    hud_thread.start()
    
    # Wait for server to start
    time.sleep(3)
    
    # Open browser to HUD
    hud_url = "http://localhost:8085"
    print(f"üåê Opening HUD: {hud_url}")
    webbrowser.open(hud_url)
    
    # Start the simulation
    time.sleep(2)
    run_simulation()

if __name__ == "__main__":
    main()
