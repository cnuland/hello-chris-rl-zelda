{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ray RLlib Training for Zelda Oracle of Seasons\n",
        "\n",
        "This notebook deploys a Ray cluster on OpenShift/Kubernetes and submits a distributed training job.\n",
        "\n",
        "Based on the Double Dragon KubeRay implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è RBAC Setup Required\n",
        "\n",
        "**Before running this notebook**, you need to grant RBAC permissions to the service account.\n",
        "\n",
        "Run these commands in a terminal:\n",
        "\n",
        "```bash\n",
        "cd /Users/cnuland/hello-chris-rl-llm-zelda\n",
        "\n",
        "# Apply RBAC permissions\n",
        "oc apply -f ops/openshift/rbac.yaml\n",
        "\n",
        "# Verify permissions\n",
        "oc auth can-i list rayclusters --as=system:serviceaccount:zelda-hybrid-rl-llm:zelda-rl-training -n zelda-hybrid-rl-llm\n",
        "oc auth can-i create rayclusters --as=system:serviceaccount:zelda-hybrid-rl-llm:zelda-rl-training -n zelda-hybrid-rl-llm\n",
        "```\n",
        "\n",
        "All should return `yes` ‚úÖ\n",
        "\n",
        "**Then proceed with the cells below.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install codeflare-sdk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Updated imports for newer codeflare_sdk versions\n",
        "from codeflare_sdk.cluster.cluster import Cluster, ClusterConfiguration\n",
        "from codeflare_sdk.cluster.auth import TokenAuthentication\n",
        "import os\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Authenticate with OpenShift\n",
        "# Get your token: oc whoami -t\n",
        "# Get your server: oc cluster-info\n",
        "\n",
        "auth = TokenAuthentication(\n",
        "    token = 'YOUR_TOKEN_HERE',  # Replace with: oc whoami -t\n",
        "    server = 'YOUR_SERVER_HERE',  # Replace with: oc cluster-info\n",
        "    skip_tls=False\n",
        ")\n",
        "auth.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, let's check what parameters ClusterConfiguration actually accepts\n",
        "import inspect\n",
        "sig = inspect.signature(ClusterConfiguration.__init__)\n",
        "print(\"Available ClusterConfiguration parameters:\")\n",
        "for param_name, param in sig.parameters.items():\n",
        "    if param_name != 'self':\n",
        "        default = param.default if param.default != inspect.Parameter.empty else \"REQUIRED\"\n",
        "        print(f\"  {param_name}: {default}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure Ray Cluster\n",
        "# ‚úÖ REUSING the Double Dragon image - it already has everything we need!\n",
        "# üéÆ PyBoy emulator works great on CPU - no GPUs needed!\n",
        "# ‚úÖ Ultra-minimal resources to guarantee scheduling on available nodes!\n",
        "\n",
        "cluster = Cluster(ClusterConfiguration(\n",
        "    name='zelda-rl',\n",
        "    namespace='zelda-hybrid-rl-llm',\n",
        "    num_workers=2,                    # ‚úÖ Reduce from 3 to 2\n",
        "    worker_cpu_requests=1,            # ‚úÖ Reduce from 8 to 1  \n",
        "    worker_cpu_limits=2,              # ‚úÖ Reduce from higher to 2\n",
        "    worker_memory_requests=\"2Gi\",     # ‚úÖ Reduce from 12Gi to 2Gi\n",
        "    worker_memory_limits=\"4Gi\",       # ‚úÖ Reduce from 16Gi to 4Gi\n",
        "    head_cpu_requests=1,              # ‚úÖ Small head node\n",
        "    head_cpu_limits=2,\n",
        "    head_memory_requests=\"2Gi\",\n",
        "    head_memory_limits=\"4Gi\",\n",
        "    \n",
        "    # No GPUs needed - PyBoy runs great on CPU!\n",
        "    num_gpus=0,\n",
        "    \n",
        "    # ‚úÖ Using your existing DD image\n",
        "    image=\"quay.io/cnuland/dd-kuberay-worker:latest\",\n",
        "))\n",
        "\n",
        "print(f\"‚úÖ Cluster configuration created:\")\n",
        "print(f\"   Name: {cluster.config.name}\")\n",
        "print(f\"   Namespace: {cluster.config.namespace}\")\n",
        "print(f\"   Workers: {cluster.config.num_workers}\")\n",
        "print(f\"   Worker CPUs: 1 request, 2 limit\")\n",
        "print(f\"   Worker Memory: 2-4 GB\")\n",
        "print(f\"   Head CPUs: 1 request, 2 limit\")\n",
        "print(f\"   Head Memory: 2-4 GB\")\n",
        "print(f\"   Image: {cluster.config.image}\")\n",
        "print(f\"   Total pods: 3 (1 head + 2 workers)\")\n",
        "print(f\"   Total resources: 3-6 CPUs, 6-12 GB RAM\")\n",
        "print(f\"   Parallel games: 6 (3 per worker)\")\n",
        "print(f\"\\n‚úÖ Ultra-minimal resources - should fit on any available nodes!\")\n",
        "print(f\"‚úÖ Kueue queues (zelda-ray-queue ‚Üí ray-cluster-queue) are ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the Ray cluster\n",
        "print(\"Creating Ray cluster...\")\n",
        "cluster.up()\n",
        "\n",
        "# Check status immediately\n",
        "print(\"\\nChecking cluster status...\")\n",
        "status_info = cluster.status()\n",
        "print(f\"Status: {status_info}\")\n",
        "\n",
        "# Try to wait for ready (with better error handling)\n",
        "try:\n",
        "    print(\"\\nWaiting for cluster to be ready...\")\n",
        "    cluster.wait_ready(timeout=600)  # 10 minute timeout\n",
        "    print(\"‚úÖ Cluster is ready!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error waiting for cluster: {e}\")\n",
        "    print(\"\\nCluster details:\")\n",
        "    print(cluster.details())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diagnostic: Check cluster status and image pull issues\n",
        "import subprocess\n",
        "\n",
        "print(\"üîç DIAGNOSTIC: Checking Ray cluster deployment...\\n\")\n",
        "\n",
        "try:\n",
        "    # Check RayCluster resource\n",
        "    print(\"1Ô∏è‚É£ RayCluster resource:\")\n",
        "    result = subprocess.run(\n",
        "        [\"oc\", \"get\", \"raycluster\", \"-n\", \"zelda-hybrid-rl-llm\"],\n",
        "        capture_output=True, text=True, timeout=10\n",
        "    )\n",
        "    print(result.stdout if result.returncode == 0 else result.stderr)\n",
        "    \n",
        "    # Check pods\n",
        "    print(\"\\n2Ô∏è‚É£ Pods in namespace:\")\n",
        "    result2 = subprocess.run(\n",
        "        [\"oc\", \"get\", \"pods\", \"-n\", \"zelda-hybrid-rl-llm\"],\n",
        "        capture_output=True, text=True, timeout=10\n",
        "    )\n",
        "    print(result2.stdout if result2.returncode == 0 else result2.stderr)\n",
        "    \n",
        "    # Check for image pull errors in events\n",
        "    print(\"\\n3Ô∏è‚É£ Recent events (looking for ImagePullBackOff errors):\")\n",
        "    result3 = subprocess.run(\n",
        "        [\"oc\", \"get\", \"events\", \"-n\", \"zelda-hybrid-rl-llm\", \n",
        "         \"--sort-by=.lastTimestamp\", \"--field-selector=type=Warning\"],\n",
        "        capture_output=True, text=True, timeout=10\n",
        "    )\n",
        "    events = result3.stdout if result3.returncode == 0 else result3.stderr\n",
        "    print(events if events.strip() else \"No warning events found\")\n",
        "    \n",
        "    # Check image pull secrets\n",
        "    print(\"\\n4Ô∏è‚É£ Image pull secrets in namespace:\")\n",
        "    result4 = subprocess.run(\n",
        "        [\"oc\", \"get\", \"secrets\", \"-n\", \"zelda-hybrid-rl-llm\", \n",
        "         \"-o\", \"jsonpath={.items[?(@.type==\\\"kubernetes.io/dockerconfigjson\\\")].metadata.name}\"],\n",
        "        capture_output=True, text=True, timeout=10\n",
        "    )\n",
        "    secrets = result4.stdout if result4.returncode == 0 else result4.stderr\n",
        "    print(secrets if secrets.strip() else \"‚ö†Ô∏è  No dockerconfigjson secrets found!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error running diagnostic commands: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üí° IMAGE PULL FIX:\")\n",
        "print(\"=\"*60)\n",
        "print(\"If you see 'ImagePullBackOff' errors, you need to:\")\n",
        "print(\"1. Check if quay.io/cnuland/dd-kuberay-worker:latest exists\")\n",
        "print(\"2. If private, create image pull secret:\")\n",
        "print(\"   oc create secret docker-registry quay-pull-secret \\\\\")\n",
        "print(\"     --docker-server=quay.io \\\\\")\n",
        "print(\"     --docker-username=YOUR_USERNAME \\\\\")\n",
        "print(\"     --docker-password=YOUR_PASSWORD \\\\\")\n",
        "print(\"     -n zelda-hybrid-rl-llm\")\n",
        "print(\"3. Then add to ClusterConfiguration:\")\n",
        "print(\"   image_pull_secrets=['quay-pull-secret']\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get cluster details and submit job\n",
        "clusterDetails = cluster.details()\n",
        "print(f\"Ray Dashboard URL: {clusterDetails.dashboard}\")\n",
        "\n",
        "client = cluster.job_client\n",
        "\n",
        "# Configure environment variables\n",
        "env_vars = {\n",
        "    # S3 Storage (MinIO)\n",
        "    'S3_ACCESS_KEY_ID': 'YOUR_S3_KEY',\n",
        "    'S3_SECRET_ACCESS_KEY': 'YOUR_S3_SECRET',\n",
        "    'S3_REGION_NAME': 'region',\n",
        "    'S3_ENDPOINT_URL': 'YOUR_S3_ENDPOINT',\n",
        "    'S3_BUCKET_NAME': 'YOUR_BUCKET_NAME',\n",
        "    \n",
        "    # LLM endpoint (assumes LLM service deployed in cluster)\n",
        "    'LLM_ENDPOINT': 'http://llama4-scout-service:8000/v1/chat/completions',\n",
        "}\n",
        "\n",
        "# Submit training job\n",
        "# Ray's working_dir uploads our Zelda code to all workers!\n",
        "submission_id = client.submit_job(\n",
        "    entrypoint=\"python run-ray-zelda.py\",\n",
        "    runtime_env={\n",
        "        \"env_vars\": env_vars,\n",
        "        'working_dir': './',  # Uploads our Zelda code, configs, and ROMs\n",
        "        'pip': [],  # DD image already has everything!\n",
        "        \"excludes\": [\"*.sh\", \"*.ipynb\", \"*.md\", \"__pycache__\", \"*.pyc\", \"checkpoints/\", \"training_runs/\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Job submitted successfully!\")\n",
        "print(f\"Submission ID: {submission_id}\")\n",
        "print(f\"Monitor at: {clusterDetails.dashboard}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor job status\n",
        "from ray.job_submission import JobStatus\n",
        "\n",
        "while True:\n",
        "    status = client.get_job_status(submission_id)\n",
        "    print(f\"Job status: {status}\")\n",
        "    \n",
        "    if status in [JobStatus.SUCCEEDED, JobStatus.FAILED, JobStatus.STOPPED]:\n",
        "        print(f\"\\nüìä Final job logs:\\n{client.get_job_logs(submission_id)}\")\n",
        "        break\n",
        "    \n",
        "    time.sleep(30)  # Check every 30 seconds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get job logs (anytime)\n",
        "logs = client.get_job_logs(submission_id)\n",
        "print(logs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up (when training is complete)\n",
        "# cluster.down()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
