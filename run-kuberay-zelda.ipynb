{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ray RLlib Training for Zelda Oracle of Seasons\n",
        "\n",
        "This notebook deploys a Ray cluster on OpenShift/Kubernetes and submits a distributed training job.\n",
        "\n",
        "Based on the Double Dragon KubeRay implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install codeflare-sdk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Updated imports for newer codeflare_sdk versions\n",
        "from codeflare_sdk.cluster.cluster import Cluster, ClusterConfiguration\n",
        "from codeflare_sdk.cluster.auth import TokenAuthentication\n",
        "import os\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Authenticate with OpenShift\n",
        "# Get your token: oc whoami -t\n",
        "# Get your server: oc cluster-info\n",
        "\n",
        "auth = TokenAuthentication(\n",
        "    token = 'YOUR_TOKEN_HERE',  # Replace with: oc whoami -t\n",
        "    server = 'YOUR_SERVER_HERE',  # Replace with: oc cluster-info\n",
        "    skip_tls=False\n",
        ")\n",
        "auth.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, let's check what parameters ClusterConfiguration actually accepts\n",
        "import inspect\n",
        "sig = inspect.signature(ClusterConfiguration.__init__)\n",
        "print(\"Available ClusterConfiguration parameters:\")\n",
        "for param_name, param in sig.parameters.items():\n",
        "    if param_name != 'self':\n",
        "        default = param.default if param.default != inspect.Parameter.empty else \"REQUIRED\"\n",
        "        print(f\"  {param_name}: {default}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure Ray Cluster\n",
        "# âœ… REUSING the Double Dragon image - it already has everything we need!\n",
        "# ðŸŽ® PyBoy emulator works great on CPU - no GPUs needed!\n",
        "\n",
        "cluster = Cluster(ClusterConfiguration(\n",
        "    name='zelda-rl',\n",
        "    namespace='zelda-hybrid-rl-llm',\n",
        "    num_workers=3,\n",
        "    \n",
        "    # CPU resources (applies to both head and workers)\n",
        "    min_cpus=8,\n",
        "    max_cpus=8,\n",
        "    \n",
        "    # Memory resources in GB (applies to both head and workers)\n",
        "    min_memory=12,\n",
        "    max_memory=16,\n",
        "    \n",
        "    # No GPUs needed - PyBoy runs great on CPU!\n",
        "    num_gpus=0,\n",
        "    \n",
        "    # âœ… Reusing DD image - has Ray, PyTorch, PyBoy, all dependencies\n",
        "    image=\"quay.io/cnuland/dd-kuberay-worker:latest\",\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the Ray cluster\n",
        "cluster.up()\n",
        "cluster.wait_ready()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get cluster details and submit job\n",
        "clusterDetails = cluster.details()\n",
        "print(f\"Ray Dashboard URL: {clusterDetails.dashboard}\")\n",
        "\n",
        "client = cluster.job_client\n",
        "\n",
        "# Configure environment variables\n",
        "env_vars = {\n",
        "    # S3 Storage (MinIO)\n",
        "    'S3_ACCESS_KEY_ID': 'YOUR_S3_KEY',\n",
        "    'S3_SECRET_ACCESS_KEY': 'YOUR_S3_SECRET',\n",
        "    'S3_REGION_NAME': 'region',\n",
        "    'S3_ENDPOINT_URL': 'YOUR_S3_ENDPOINT',\n",
        "    'S3_BUCKET_NAME': 'YOUR_BUCKET_NAME',\n",
        "    \n",
        "    # LLM endpoint (assumes LLM service deployed in cluster)\n",
        "    'LLM_ENDPOINT': 'http://llama4-scout-service:8000/v1/chat/completions',\n",
        "}\n",
        "\n",
        "# Submit training job\n",
        "# Ray's working_dir uploads our Zelda code to all workers!\n",
        "submission_id = client.submit_job(\n",
        "    entrypoint=\"python run-ray-zelda.py\",\n",
        "    runtime_env={\n",
        "        \"env_vars\": env_vars,\n",
        "        'working_dir': './',  # Uploads our Zelda code, configs, and ROMs\n",
        "        'pip': [],  # DD image already has everything!\n",
        "        \"excludes\": [\"*.sh\", \"*.ipynb\", \"*.md\", \"__pycache__\", \"*.pyc\", \"checkpoints/\", \"training_runs/\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Job submitted successfully!\")\n",
        "print(f\"Submission ID: {submission_id}\")\n",
        "print(f\"Monitor at: {clusterDetails.dashboard}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor job status\n",
        "from ray.job_submission import JobStatus\n",
        "\n",
        "while True:\n",
        "    status = client.get_job_status(submission_id)\n",
        "    print(f\"Job status: {status}\")\n",
        "    \n",
        "    if status in [JobStatus.SUCCEEDED, JobStatus.FAILED, JobStatus.STOPPED]:\n",
        "        print(f\"\\nðŸ“Š Final job logs:\\n{client.get_job_logs(submission_id)}\")\n",
        "        break\n",
        "    \n",
        "    time.sleep(30)  # Check every 30 seconds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get job logs (anytime)\n",
        "logs = client.get_job_logs(submission_id)\n",
        "print(logs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up (when training is complete)\n",
        "# cluster.down()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
